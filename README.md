# REIMPLEMENTATION-AND-COMPARISON-OF-HYBRIDSN-MODEL-WITH-OTHER-EXISTING-SUGGESTIONS-FOR-HYPERSPECTRAL-IMAGES

Hyperspectral Images have high significance in scientific fields and are very useful in various fields. These images contain various features that drive and derive different conclusions. Various methods have been suggested over time to deal with HSI (hyperspectral images). HSI has gained a lot of attention in recent times. They contain a lot of important data. They may be geological, medical, biological, astronomical or surveillance. These images are multi-dimensional with a lot of features and usually contain many features.

Usually, 3D Convolution Neural Networks are used to extract features from multi-dimensional images such as HSI, CT scans and videos. The use of 3D CNN is rare in the field of AI/ML and hybrid CNN is even more rare. The development of hybrid models can be extended to tackle many challenges in a similar field.  Initially a complete 3D Convolution Neural Network was suggested for classification of HSI.

Among them, different ways of pre-processing were suggested to decrease the dimensionality and get better results. Later on, hybrid CNN models were suggested (HybridSN), which are combinations of both 2D and 3D CNNs. Since 3D CNNs require more computational power and time, hybrid models are introduced to reduce the time and increase the accuracy in an efficient manner. 

This paper deals with different pre-processing techniques such as PCA (Principal Component Analysis), LDA (Linear Discriminant Analysis) and activation functions such as LeakyRelu and Mesh functions. The above paper dominantly deals with the reimplementation of ‘Supervised Linear Discriminant Analysis for Dimension Reduction and Hyperspectral Image Classification Method Based on 2D-3D CNN’. In the mentioned paper, it suggests LDA pre-processing technique over PCA (which was used originally) and Mish activation function. The paper mentions model architecture. In this paper, the model is reimplemented by changing different variables and combinations. Previously, ReLu activation was used and the paper suggestd Mish activation. This paper deals with LeakyReLu activation to compare the results with previous papers results.
